# ğŸ§ª aicubench

aicubench is an open, standard benchmark toolset for PAISC workloads (Image, Video, Audio, Speech-to-Text, LLM) across platforms (Mac/Windows/Linux) and models (Stable Diffusion, AnimateDiff, Style-Bert-VITS2, Whisper, etc.).

This repository allows reproducible benchmarking using real-world prompts and datasets from Hugging Face AICU/aicubench, with results exportable to HTML and JSON for public publishing.

## ğŸ”§ Quick Start (macOS)

### 1. Clone the repository

```bash
git clone https://github.com/yourname/aicubench.git
cd aicubench
```

### 2. Run the setup script

This will:
- Create a virtual environment (`.venv`)
- Activate it
- Install `aicubench` in editable mode
- Run a sample benchmark

```bash
bash scripts/setup.sh
```

### 3. Next time activation

To use `aicubench` later:

```bash
source .venv/bin/activate
```

Then you can run:

```bash
aicubench all --prompt "1girl" --it 10
```


ğŸ–¼ Benchmark Targets
	â€¢	Image generation: Stable Diffusion 1.5, SDXL, FLUX.1
	â€¢	Video generation: AnimateDiff, Wan2.1, HunyuanVideo
	â€¢	Audio synthesis: Style-Bert VITS2
	â€¢	Speech-to-text: Whisper, Audapolis
	â€¢	LLMs: SOTA models evaluated on MMLU, GSM8K, etc.

â¸»

ğŸ“¦ Installation (Alternative)

To install via pip (editable mode):

python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install -e .


â¸»

âš–ï¸ License

This project is licensed under the Apache License 2.0. See LICENSE for details.

â¸»

README.ja.md ã«ã¯ä¸Šè¨˜ã®å†…å®¹ã‚’æ—¥æœ¬èªã§ç¿»è¨³ã—ã¦è¨˜è¼‰å¯èƒ½ã§ã™ã€‚å¿…è¦ã§ã‚ã‚Œã°ç¿»è¨³ã‚‚è¡Œã„ã¾ã™ã€‚ç¶šãã‚’å¸Œæœ›ã•ã‚Œã¾ã™ã‹ï¼Ÿ